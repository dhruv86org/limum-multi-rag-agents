{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent RAG Orchestration System\n",
    "\n",
    "## Overview\n",
    "This notebook implements a production-grade multi-agent system that:\n",
    "1. **Classifies** user queries by intent using an orchestrator agent\n",
    "2. **Routes** queries to specialized RAG agents (HR, Tech, Finance)\n",
    "3. **Traces** all workflows with Langfuse for debugging and monitoring\n",
    "4. **Evaluates** responses for quality using automated scoring\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "User Query ‚Üí Orchestrator (Intent Classification)\n",
    "                    ‚Üì\n",
    "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        ‚Üì           ‚Üì           ‚Üì\n",
    "    HR Agent    Tech Agent  Finance Agent\n",
    "        ‚Üì           ‚Üì           ‚Üì\n",
    "    HR Docs     Tech Docs   Finance Docs\n",
    "    (Vector)    (Vector)    (Vector)\n",
    "```\n",
    "\n",
    "All agents use LangChain for production-grade components and Langfuse for complete observability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All imports successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain imports (updated for LangChain 1.1.0+)\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Langfuse for tracing\n",
    "from langfuse.langchain import CallbackHandler\n",
    "from langfuse import Langfuse\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Missing environment variables: LANGFUSE_HOST\n",
      "Please copy .env.example to .env and fill in your API keys\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "# Force reload to pick up any changes to .env\n",
    "import sys\n",
    "if '.env' in sys.modules:\n",
    "    del sys.modules['.env']\n",
    "    \n",
    "load_dotenv(override=True)  # override=True forces reload of existing env vars\n",
    "\n",
    "# Verify required environment variables\n",
    "required_vars = [\n",
    "    'OPENAI_API_KEY',\n",
    "    'OPENAI_API_BASE',\n",
    "    'LANGFUSE_PUBLIC_KEY',\n",
    "    'LANGFUSE_SECRET_KEY',\n",
    "    'LANGFUSE_HOST'\n",
    "]\n",
    "\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    print(f\"‚ö†Ô∏è  Missing environment variables: {', '.join(missing_vars)}\")\n",
    "    print(\"Please copy .env.example to .env and fill in your API keys\")\n",
    "else:\n",
    "    print(\"‚úì All environment variables configured\")\n",
    "    print(f\"  - Using OpenRouter API: {os.getenv('OPENAI_API_BASE')}\")\n",
    "    print(f\"  - Langfuse enabled: {os.getenv('LANGFUSE_HOST')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç API Credentials Check:\n",
      "============================================================\n",
      "‚úÖ OPENAI_API_KEY is set\n",
      "   First 15 chars: sk-or-v1-d64216...\n",
      "   ‚úÖ Format looks correct for OpenRouter\n",
      "\n",
      "‚úÖ OPENAI_API_BASE is set: https://openrouter.ai/api/v1\n",
      "\n",
      "============================================================\n",
      "\n",
      "üí° If you see errors:\n",
      "   1. Check your .env file has: OPENAI_API_KEY=sk-or-v1-...\n",
      "   2. Verify your OpenRouter API key at https://openrouter.ai/keys\n",
      "   3. Make sure your .env file is in the project root directory\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: Verify API credentials\n",
    "print(\"\\nüîç API Credentials Check:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "api_base = os.getenv('OPENAI_API_BASE')\n",
    "\n",
    "if api_key:\n",
    "    print(f\"‚úÖ OPENAI_API_KEY is set\")\n",
    "    print(f\"   First 15 chars: {api_key[:15]}...\")\n",
    "    if api_key.startswith('sk-or-v1-'):\n",
    "        print(\"   ‚úÖ Format looks correct for OpenRouter\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  Key doesn't start with 'sk-or-v1-' (expected for OpenRouter)\")\n",
    "else:\n",
    "    print(\"‚ùå OPENAI_API_KEY is NOT set!\")\n",
    "    print(\"   Please check your .env file\")\n",
    "\n",
    "if api_base:\n",
    "    print(f\"\\n‚úÖ OPENAI_API_BASE is set: {api_base}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå OPENAI_API_BASE is NOT set!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nüí° If you see errors:\")\n",
    "print(\"   1. Check your .env file has: OPENAI_API_KEY=sk-or-v1-...\")\n",
    "print(\"   2. Verify your OpenRouter API key at https://openrouter.ai/keys\")\n",
    "print(\"   3. Make sure your .env file is in the project root directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration loaded:\n",
      "  - model_name: openai/gpt-4-turbo-preview\n",
      "  - embedding_model: openai/text-embedding-ada-002\n",
      "  - temperature: 0.1\n",
      "  - chunk_size: 1000\n",
      "  - chunk_overlap: 200\n",
      "  - retrieval_k: 5\n",
      "  - data_dir: data\n",
      "  - vector_store_dir: vector_stores\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'model_name': os.getenv('OPENAI_MODEL', 'openai/gpt-4-turbo-preview'),\n",
    "    'embedding_model': os.getenv('EMBEDDING_MODEL', 'openai/text-embedding-ada-002'),\n",
    "    'temperature': 0.1,  # Low temperature for consistent routing\n",
    "    'chunk_size': 1000,\n",
    "    'chunk_overlap': 200,\n",
    "    'retrieval_k': 5,  # Number of documents to retrieve\n",
    "    'data_dir': Path('data'),\n",
    "    'vector_store_dir': Path('vector_stores')\n",
    "}\n",
    "\n",
    "# Create vector store directory if it doesn't exist\n",
    "CONFIG['vector_store_dir'].mkdir(exist_ok=True)\n",
    "\n",
    "print(\"‚úì Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Document Loading & Vector Store Creation\n",
    "\n",
    "We load documents from three specialized knowledge bases:\n",
    "- **HR Documents**: Employee policies, benefits, leave policies\n",
    "- **Tech Documents**: API docs, deployment guides, security standards  \n",
    "- **Finance Documents**: Expense policies, budgets, procurement\n",
    "\n",
    "Each is chunked and embedded into a separate FAISS vector store for efficient semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Document loading functions defined\n"
     ]
    }
   ],
   "source": [
    "def load_documents_from_directory(directory: Path) -> List[Document]:\n",
    "    \"\"\"Load all markdown documents from a directory.\"\"\"\n",
    "    loader = DirectoryLoader(\n",
    "        str(directory),\n",
    "        glob=\"**/*.md\",\n",
    "        loader_cls=TextLoader,\n",
    "        show_progress=True\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    print(f\"  Loaded {len(documents)} documents from {directory.name}\")\n",
    "    return documents\n",
    "\n",
    "def create_vector_store(documents: List[Document], store_name: str) -> FAISS:\n",
    "    \"\"\"Create and persist a FAISS vector store from documents.\"\"\"\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CONFIG['chunk_size'],\n",
    "        chunk_overlap=CONFIG['chunk_overlap'],\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"  Split into {len(chunks)} chunks\")\n",
    "    \n",
    "    # Create embeddings\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    print(f\"  Using local embeddings model\")\n",
    "    \n",
    "    # Create vector store\n",
    "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "    \n",
    "    # Save to disk\n",
    "    store_path = CONFIG['vector_store_dir'] / store_name\n",
    "    vector_store.save_local(str(store_path))\n",
    "    print(f\"  ‚úì Vector store saved to {store_path}\")\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "print(\"‚úì Document loading functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Creating Vector Stores\n",
      "============================================================\n",
      "\n",
      "[1/3] HR Documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 583.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 3 documents from hr_docs\n",
      "  Split into 36 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using local embeddings model\n",
      "  ‚úì Vector store saved to vector_stores/hr_vector_store\n",
      "\n",
      "[2/3] Tech Documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 1892.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 3 documents from tech_docs\n",
      "  Split into 69 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using local embeddings model\n",
      "  ‚úì Vector store saved to vector_stores/tech_vector_store\n",
      "\n",
      "[3/3] Finance Documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 2896.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 3 documents from finance_docs\n",
      "  Split into 65 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using local embeddings model\n",
      "  ‚úì Vector store saved to vector_stores/finance_vector_store\n",
      "\n",
      "============================================================\n",
      "‚úì All vector stores created successfully\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load and create vector stores for each domain\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Creating Vector Stores\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vector_stores = {}\n",
    "\n",
    "# HR Documents\n",
    "print(\"\\n[1/3] HR Documents\")\n",
    "hr_docs = load_documents_from_directory(CONFIG['data_dir'] / 'hr_docs')\n",
    "vector_stores['hr'] = create_vector_store(hr_docs, 'hr_vector_store')\n",
    "\n",
    "# Tech Documents\n",
    "print(\"\\n[2/3] Tech Documents\")\n",
    "tech_docs = load_documents_from_directory(CONFIG['data_dir'] / 'tech_docs')\n",
    "vector_stores['tech'] = create_vector_store(tech_docs, 'tech_vector_store')\n",
    "\n",
    "# Finance Documents\n",
    "print(\"\\n[3/3] Finance Documents\")\n",
    "finance_docs = load_documents_from_directory(CONFIG['data_dir'] / 'finance_docs')\n",
    "vector_stores['finance'] = create_vector_store(finance_docs, 'finance_vector_store')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì All vector stores created successfully\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Agent Definitions\n",
    "\n",
    "Each specialized agent is a RAG system with:\n",
    "- Domain-specific vector store retriever\n",
    "- Custom prompt template\n",
    "- LangChain RetrievalQA chain\n",
    "- Langfuse tracing integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Langfuse tracing enabled\n",
      "\n",
      "üîê Verifying API credentials...\n",
      "‚úÖ API Key present: sk-or-v1-d64216...5895\n",
      "‚úÖ API Base: https://openrouter.ai/api/v1\n",
      "\n",
      "ü§ñ Initializing LLM...\n",
      "‚úì LLM initialized with model: openai/gpt-4-turbo-preview\n"
     ]
    }
   ],
   "source": [
    "# Initialize Langfuse callback handler (OPTIONAL)\n",
    "# Note: Langfuse v3+ uses environment variables automatically\n",
    "# If Langfuse credentials are invalid, tracing will be disabled but the system will still work\n",
    "\n",
    "try:\n",
    "    langfuse_handler = CallbackHandler()\n",
    "    print(\"‚úÖ Langfuse tracing enabled\")\n",
    "    USE_LANGFUSE = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Langfuse initialization failed: {e}\")\n",
    "    print(\"   Continuing without tracing (this is OK for testing)\")\n",
    "    langfuse_handler = None\n",
    "    USE_LANGFUSE = False\n",
    "\n",
    "# Verify API credentials before initializing LLM\n",
    "print(\"\\nüîê Verifying API credentials...\")\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "api_base = os.getenv('OPENAI_API_BASE')\n",
    "\n",
    "if not api_key or not api_base:\n",
    "    raise ValueError(\"‚ùå Missing OPENAI_API_KEY or OPENAI_API_BASE in environment variables!\")\n",
    "\n",
    "print(f\"‚úÖ API Key present: {api_key[:15]}...{api_key[-4:]}\")\n",
    "print(f\"‚úÖ API Base: {api_base}\")\n",
    "\n",
    "# Initialize LLM\n",
    "print(\"\\nü§ñ Initializing LLM...\")\n",
    "llm = ChatOpenAI(\n",
    "    model=CONFIG['model_name'],\n",
    "    temperature=CONFIG['temperature'],\n",
    "    api_key=api_key,\n",
    "    base_url=api_base\n",
    ")\n",
    "\n",
    "print(f\"‚úì LLM initialized with model: {CONFIG['model_name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Agent prompts defined\n"
     ]
    }
   ],
   "source": [
    "# Define prompt templates for each agent\n",
    "\n",
    "HR_PROMPT = PromptTemplate(\n",
    "    template=\"\"\"You are TechCorp's HR Assistant, an expert on employee policies, benefits, and workplace procedures.\n",
    "\n",
    "Use the following context from our HR documentation to answer the question. If you don't find the answer in the context, say so - don't make up information.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a clear, accurate answer based on the context above. Include specific policy details, numbers, and procedures when available. If the answer requires follow-up with HR, mention that.\n",
    "\n",
    "Answer:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "TECH_PROMPT = PromptTemplate(\n",
    "    template=\"\"\"You are TechCorp's Technical Documentation Assistant, an expert on APIs, deployment, and engineering practices.\n",
    "\n",
    "Use the following context from our technical documentation to answer the question. Provide code examples and technical details when helpful.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a comprehensive technical answer. Include:\n",
    "- Step-by-step instructions when applicable\n",
    "- Code examples or configuration snippets\n",
    "- Best practices and important warnings\n",
    "- Links to related documentation when relevant\n",
    "\n",
    "If you don't find the answer in the context, say so clearly.\n",
    "\n",
    "Answer:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "FINANCE_PROMPT = PromptTemplate(\n",
    "    template=\"\"\"You are TechCorp's Finance Assistant, an expert on budgets, expenses, and financial policies.\n",
    "\n",
    "Use the following context from our financial documentation to answer the question. Be precise with numbers, limits, and approval requirements.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a clear, accurate answer including:\n",
    "- Specific dollar amounts and limits\n",
    "- Required approvals and procedures\n",
    "- Relevant policy sections\n",
    "- Important exceptions or special cases\n",
    "\n",
    "If you don't find the answer in the context, say so - don't make up financial information.\n",
    "\n",
    "Answer:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "print(\"‚úì Agent prompts defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating specialized RAG agents...\n",
      "  ‚úì HR agent created\n",
      "  ‚úì Tech agent created\n",
      "  ‚úì Finance agent created\n",
      "\n",
      "‚úì All RAG agents ready\n"
     ]
    }
   ],
   "source": [
    "# Create RAG agents for each domain\n",
    "\n",
    "def create_rag_agent(vector_store: FAISS, prompt: PromptTemplate, agent_name: str) -> RetrievalQA:\n",
    "    \"\"\"Create a RetrievalQA agent with the given vector store and prompt.\"\"\"\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": CONFIG['retrieval_k']}\n",
    "    )\n",
    "    \n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "    \n",
    "    print(f\"  ‚úì {agent_name} agent created\")\n",
    "    return chain\n",
    "\n",
    "print(\"\\nCreating specialized RAG agents...\")\n",
    "\n",
    "agents = {\n",
    "    'hr': create_rag_agent(vector_stores['hr'], HR_PROMPT, \"HR\"),\n",
    "    'tech': create_rag_agent(vector_stores['tech'], TECH_PROMPT, \"Tech\"),\n",
    "    'finance': create_rag_agent(vector_stores['finance'], FINANCE_PROMPT, \"Finance\")\n",
    "}\n",
    "\n",
    "print(\"\\n‚úì All RAG agents ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Orchestrator & Routing\n",
    "\n",
    "The orchestrator analyzes user queries and routes them to the appropriate specialized agent.\n",
    "\n",
    "**Routing Strategy:**\n",
    "- Uses LLM to classify intent from query\n",
    "- Categories: HR, Tech, Finance, General\n",
    "- Confidence scoring to detect ambiguous queries\n",
    "- Fallback to general response if no clear match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Orchestrator classification function defined\n"
     ]
    }
   ],
   "source": [
    "# Orchestrator prompt for intent classification\n",
    "ORCHESTRATOR_PROMPT = \"\"\"You are a query classification system for TechCorp's knowledge base.\n",
    "\n",
    "Analyze the user's question and classify it into ONE of these categories:\n",
    "\n",
    "**HR**: Questions about:\n",
    "- Employee benefits, PTO, sick leave, parental leave\n",
    "- Company policies, workplace rules, dress code\n",
    "- Onboarding, hiring, termination procedures\n",
    "- Performance reviews, compensation\n",
    "- Holidays, working hours, remote work\n",
    "\n",
    "**TECH**: Questions about:\n",
    "- API documentation, endpoints, authentication\n",
    "- Deployment procedures, CI/CD, infrastructure\n",
    "- Security standards, best practices, compliance\n",
    "- Code examples, technical implementation\n",
    "- System architecture, monitoring, troubleshooting\n",
    "\n",
    "**FINANCE**: Questions about:\n",
    "- Expense policies, reimbursement procedures\n",
    "- Budget planning, approval limits\n",
    "- Procurement, vendor management\n",
    "- Travel expenses, meal allowances\n",
    "- Corporate cards, invoicing\n",
    "\n",
    "**GENERAL**: Questions that:\n",
    "- Don't fit the above categories\n",
    "- Are greetings or casual conversation\n",
    "- Are too vague to categorize\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Respond with ONLY the category name (HR, TECH, FINANCE, or GENERAL). No explanation needed.\n",
    "\n",
    "Category:\"\"\"\n",
    "\n",
    "def classify_intent(question: str) -> str:\n",
    "    \"\"\"Classify the user's question into a category.\"\"\"\n",
    "    response = llm.invoke(\n",
    "        ORCHESTRATOR_PROMPT.format(question=question),\n",
    "        config={\"callbacks\": [langfuse_handler]}\n",
    "    )\n",
    "    category = response.content.strip().upper()\n",
    "    \n",
    "    # Validate category\n",
    "    valid_categories = ['HR', 'TECH', 'FINANCE', 'GENERAL']\n",
    "    if category not in valid_categories:\n",
    "        print(f\"  ‚ö†Ô∏è  Invalid category '{category}', defaulting to GENERAL\")\n",
    "        category = 'GENERAL'\n",
    "    \n",
    "    return category\n",
    "\n",
    "print(\"‚úì Orchestrator classification function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Query routing function defined\n"
     ]
    }
   ],
   "source": [
    "def route_query(question: str, trace_name: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Main routing function that:\n",
    "    1. Classifies the query\n",
    "    2. Routes to appropriate agent\n",
    "    3. Returns structured response with metadata\n",
    "    \"\"\"\n",
    "    # Classify intent\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    category = classify_intent(question)\n",
    "    print(f\"\\nüìã Classification: {category}\")\n",
    "    \n",
    "    # Route to appropriate agent\n",
    "    if category in ['HR', 'TECH', 'FINANCE']:\n",
    "        agent_key = category.lower()\n",
    "        print(f\"üéØ Routing to {category} Agent...\\n\")\n",
    "        \n",
    "        # Query the agent with Langfuse tracing\n",
    "        result = agents[agent_key].invoke(\n",
    "            {\"query\": question},\n",
    "            config={\"callbacks\": [langfuse_handler]}\n",
    "        )\n",
    "        \n",
    "        response = {\n",
    "            'question': question,\n",
    "            'category': category,\n",
    "            'agent_used': agent_key,\n",
    "            'answer': result['result'],\n",
    "            'source_documents': result['source_documents'],\n",
    "            'num_sources': len(result['source_documents'])\n",
    "        }\n",
    "    else:\n",
    "        print(f\"üí¨ Handling as general query...\\n\")\n",
    "        # General response for non-specialized queries\n",
    "        general_response = llm.invoke(\n",
    "            f\"\"\"You are TechCorp's helpful assistant. Answer this question politely:\n",
    "            \n",
    "Question: {question}\n",
    "\n",
    "If this is a greeting, respond warmly. If it's a question outside HR, Tech, or Finance topics, explain that you specialize in those areas and offer to help with related questions.\n",
    "\n",
    "Answer:\"\"\",\n",
    "            config={\"callbacks\": [langfuse_handler]}\n",
    "        )\n",
    "        \n",
    "        response = {\n",
    "            'question': question,\n",
    "            'category': 'GENERAL',\n",
    "            'agent_used': 'general',\n",
    "            'answer': general_response.content,\n",
    "            'source_documents': [],\n",
    "            'num_sources': 0\n",
    "        }\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"‚úì Query routing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Testing & Examples\n",
    "\n",
    "Let's test the multi-agent system with queries spanning all domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Display helper defined\n"
     ]
    }
   ],
   "source": [
    "def display_response(response: Dict[str, Any]):\n",
    "    \"\"\"Pretty-print a response from the system.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESPONSE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n{response['answer']}\\n\")\n",
    "    \n",
    "    if response['num_sources'] > 0:\n",
    "        print(f\"\\nüìö Sources: {response['num_sources']} documents retrieved\")\n",
    "        print(f\"\\nTop source: {response['source_documents'][0].metadata.get('source', 'Unknown')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"‚úì Display helper defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Query: How much PTO do I get after working here for 4 years?\n",
      "============================================================\n",
      "\n",
      "üìã Classification: HR\n",
      "üéØ Routing to HR Agent...\n",
      "\n",
      "\n",
      "============================================================\n",
      "RESPONSE\n",
      "============================================================\n",
      "\n",
      "After working at TechCorp for 4 years, you are entitled to 20 days (160 hours) of Paid Time Off (PTO) per year. This is in accordance with the PTO accrual rates based on tenure, where employees in their 3rd to 5th year with the company accrue 20 days of PTO annually.\n",
      "\n",
      "\n",
      "üìö Sources: 5 documents retrieved\n",
      "\n",
      "Top source: data/hr_docs/leave_policies.md\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 1: HR Question\n",
    "response = route_query(\"How much PTO do I get after working here for 4 years?\")\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Query: How do I authenticate with the TechCorp API?\n",
      "============================================================\n",
      "\n",
      "üìã Classification: TECH\n",
      "üéØ Routing to TECH Agent...\n",
      "\n",
      "\n",
      "============================================================\n",
      "RESPONSE\n",
      "============================================================\n",
      "\n",
      "To authenticate with the TechCorp API, you need to follow a series of steps to ensure secure and successful authentication. Below are the detailed instructions, best practices, and code examples to guide you through the process.\n",
      "\n",
      "### Step 1: Obtain Your API Key\n",
      "\n",
      "1. **Log into your TechCorp account.**\n",
      "2. **Navigate to Settings > API Keys.**\n",
      "3. **Click \"Generate New API Key\".** Once generated, your API key will be displayed. It's crucial to store this key securely as it will be shown only once.\n",
      "\n",
      "### Step 2: Use the API Key for Authentication\n",
      "\n",
      "When making requests to the TechCorp API, you must include your API key in the request header for authentication.\n",
      "\n",
      "**Example Request with cURL:**\n",
      "\n",
      "```bash\n",
      "curl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n",
      "  https://api.techcorp.com/v1/users\n",
      "```\n",
      "\n",
      "Replace `YOUR_API_KEY` with your actual API key.\n",
      "\n",
      "### Best Practices for API Authentication\n",
      "\n",
      "- **Secure Storage:** Store your API keys securely and never expose them in public repositories or client-side code.\n",
      "- **Headers Over Query Strings:** Always use the API key in the request header. Placing the API key in the URL (query string) is less secure.\n",
      "- **Environment Separation:** Use separate API keys for different environments (e.g., production, staging) to minimize risks.\n",
      "- **Permission Scope:** Assign the minimum necessary permissions to each API key to follow the principle of least privilege.\n",
      "- **Regular Rotation:** Rotate your API keys every 90 days to reduce the risk of key compromise.\n",
      "- **Monitoring:** Monitor API key usage for unusual activity and revoke any keys that you suspect have been compromised.\n",
      "\n",
      "**Python Example Using Requests Library:**\n",
      "\n",
      "```python\n",
      "import requests\n",
      "\n",
      "api_key = 'YOUR_API_KEY'\n",
      "headers = {\n",
      "    'Authorization': f'Bearer {api_key}',\n",
      "    'X-API-Version': 'v1'\n",
      "}\n",
      "\n",
      "response = requests.get('https://api.techcorp.com/v1/users', headers=headers)\n",
      "print(response.json())\n",
      "```\n",
      "\n",
      "### OAuth 2.0 for Third-Party Integrations\n",
      "\n",
      "If you're developing a third-party integration, you might need to use OAuth 2.0 instead of API keys.\n",
      "\n",
      "1. **Redirect users to the authorization endpoint:**\n",
      "\n",
      "```http\n",
      "GET https://auth.techcorp.com/oauth/authorize?client_id={CLIENT_ID}&redirect_uri={REDIRECT_URI}&response_type=code&scope=read_users,write_data\n",
      "```\n",
      "\n",
      "2. **Exchange the authorization code for an access token:**\n",
      "\n",
      "```bash\n",
      "curl -X POST https://auth.techcorp.com/oauth/token \\\n",
      "-H \"Content-Type: application/json\" \\\n",
      "-d '{\n",
      "  \"grant_type\": \"authorization_code\",\n",
      "  \"code\": \"AUTH_CODE\",\n",
      "  \"client_id\": \"YOUR_CLIENT_ID\",\n",
      "  \"client_secret\": \"YOUR_CLIENT_SECRET\",\n",
      "  \"redirect_uri\": \"YOUR_REDIRECT_URI\"\n",
      "}'\n",
      "```\n",
      "\n",
      "### Important Warnings\n",
      "\n",
      "- **HTTPS Only:** All API requests must be made over HTTPS. HTTP requests will be rejected to protect data in transit.\n",
      "- **Avoid Hard-Coding Credentials:** Never hard-code your API keys or OAuth credentials in your application's source code.\n",
      "- **IP Whitelisting:** For additional security, consider IP whitelisting if your plan supports it.\n",
      "\n",
      "### Additional Resources\n",
      "\n",
      "- **API Reference:** [TechCorp API Documentation](https://docs.techcorp.com/api)\n",
      "- **Getting Started Guide:** [Quickstart Guide](https://docs.techcorp.com/quickstart)\n",
      "- **Code Examples:** [GitHub Repository](https://github.com/techcorp/examples)\n",
      "\n",
      "By following these steps and best practices, you can securely authenticate with the TechCorp API and protect your application and data from unauthorized access.\n",
      "\n",
      "\n",
      "üìö Sources: 5 documents retrieved\n",
      "\n",
      "Top source: data/tech_docs/api_documentation.md\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 2: Tech Question\n",
    "response = route_query(\"How do I authenticate with the TechCorp API?\")\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Query: What's the expense limit for business meals?\n",
      "============================================================\n",
      "\n",
      "üìã Classification: FINANCE\n",
      "üéØ Routing to FINANCE Agent...\n",
      "\n",
      "\n",
      "============================================================\n",
      "RESPONSE\n",
      "============================================================\n",
      "\n",
      "The expense limit for business meals varies depending on the meal and context, with specific dollar amounts, limits, and required approvals as follows:\n",
      "\n",
      "### Daily Meal Allowances (Per Person)\n",
      "- **Breakfast:** $20\n",
      "- **Lunch:** $25\n",
      "- **Dinner:** $50\n",
      "- **Daily Maximum:** $75\n",
      "\n",
      "### International Meal Allowances (Major Cities)\n",
      "- **Europe:**\n",
      "  - Breakfast: $25\n",
      "  - Lunch: $30\n",
      "  - Dinner: $60\n",
      "  - Daily Max: $100\n",
      "- **Asia:**\n",
      "  - Breakfast: $20\n",
      "  - Lunch: $25\n",
      "  - Dinner: $50\n",
      "  - Daily Max: $80\n",
      "- **Other Regions:** Use standard US rates unless approved otherwise.\n",
      "\n",
      "### Business Meals\n",
      "- **Client/Prospect Meals:** Requires manager approval for groups of 5 or more. Attendees and business purpose must be documented, and an itemized receipt submitted. Meals should be at reasonable locations, avoiding ultra-luxury establishments.\n",
      "- **Team Meals:** Quarterly team dinners are approved with a limit of $75 per person. Manager approval is required, and these meals are intended to celebrate milestones and achievements. Team meals are not permitted during conferences as those are covered separately.\n",
      "\n",
      "### Alcohol Policy\n",
      "- Alcohol is reimbursable during business meals only, with a limit of 2 drinks per meal at $15 per drink. Alcohol must be accompanied by food.\n",
      "\n",
      "### Tips\n",
      "- A tip of 15-20% is included in the meal cost and should adhere to this guideline.\n",
      "\n",
      "### Special Situations\n",
      "- If a client insists on an expensive restaurant, employees are advised to use judgment and document the situation in the expense report. Generally, such expenses are approved if client-driven.\n",
      "\n",
      "### Approval and Documentation Requirements\n",
      "- Receipts are required for meals over $25.\n",
      "- Pre-approval from a VP is required for entertainment expenses, which must have a clear business purpose documented, including client names and companies.\n",
      "- For personal vehicle mileage, the reimbursement rate is $0.655/mile, and starting/ending odometer readings must be logged and submitted with the expense report.\n",
      "\n",
      "### Exceptions and Special Cases\n",
      "- For meals that exceed these limits due to special circumstances (e.g., client preference for an expensive restaurant), documentation and justification in the expense report are crucial for potential approval.\n",
      "- In cases of lost receipts for small amounts (<$25), submission with an explanation may be approved, though frequent occurrences will be flagged.\n",
      "\n",
      "This comprehensive overview covers the specific dollar amounts, limits, required approvals, and procedures for business meal expenses, along with important exceptions or special cases as outlined in the provided financial documentation context.\n",
      "\n",
      "\n",
      "üìö Sources: 5 documents retrieved\n",
      "\n",
      "Top source: data/finance_docs/expense_policy.md\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 3: Finance Question\n",
    "response = route_query(\"What's the expense limit for business meals?\")\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Query: What are the security requirements for new employees?\n",
      "============================================================\n",
      "\n",
      "üìã Classification: HR\n",
      "üéØ Routing to HR Agent...\n",
      "\n",
      "\n",
      "============================================================\n",
      "RESPONSE\n",
      "============================================================\n",
      "\n",
      "The security requirements for new employees at TechCorp include the following specific policies and procedures:\n",
      "\n",
      "1. **Strong Passwords**: Employees are required to use strong passwords for all systems. These passwords must be at least 12 characters long and should be changed every 90 days to maintain security.\n",
      "\n",
      "2. **Multi-factor Authentication**: All systems must have multi-factor authentication enabled. This adds an extra layer of security by requiring not only a password and username but also something that only the user has on them, i.e., a piece of information only they should know or have immediately to hand - such as a physical token.\n",
      "\n",
      "3. **VPN for Remote Access**: Employees accessing the company's systems remotely are required to use a Virtual Private Network (VPN). This ensures that remote access is secure and that data transmitted over the internet is encrypted.\n",
      "\n",
      "4. **Reporting Suspicious Emails**: Any suspicious emails must be reported to the IT department. This is part of the company's efforts to prevent phishing attacks and other email-based security threats.\n",
      "\n",
      "These requirements are part of TechCorp's IT Security policies aimed at protecting the company's data and technology infrastructure. New employees should ensure they understand and comply with these requirements. For any clarifications or further information, they should follow up with the IT department or HR.\n",
      "\n",
      "\n",
      "üìö Sources: 5 documents retrieved\n",
      "\n",
      "Top source: data/hr_docs/employee_handbook.md\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 4: Edge case - Ambiguous\n",
    "response = route_query(\"What are the security requirements for new employees?\")\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Query: Hello! How are you?\n",
      "============================================================\n",
      "\n",
      "üìã Classification: GENERAL\n",
      "üí¨ Handling as general query...\n",
      "\n",
      "\n",
      "============================================================\n",
      "RESPONSE\n",
      "============================================================\n",
      "\n",
      "Hello! Thank you for your kind greeting. I'm here to assist you. While I don't have feelings or personal experiences, I'm ready and eager to help you with any questions or concerns you might have, especially in HR, Tech, or Finance areas. How can I assist you today?\n",
      "\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 5: General\n",
    "response = route_query(\"Hello! How are you?\")\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Langfuse Integration & Tracing\n",
    "\n",
    "All queries are automatically traced in Langfuse. You can:\n",
    "- View complete execution paths\n",
    "- Debug failed retrievals\n",
    "- Analyze routing accuracy\n",
    "- Monitor response quality\n",
    "\n",
    "Access your traces at: https://cloud.langfuse.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Recent Traces (last 5):\n",
      "\n",
      "View detailed traces at: https://cloud.langfuse.com\n",
      "\n",
      "Traces include:\n",
      "  - Intent classification step\n",
      "  - Agent selection logic\n",
      "  - Vector store retrieval\n",
      "  - LLM response generation\n",
      "  - Full execution timeline\n",
      "  - Token usage and costs\n"
     ]
    }
   ],
   "source": [
    "# Initialize Langfuse client for evaluation\n",
    "langfuse = Langfuse(\n",
    "    public_key=os.getenv('LANGFUSE_PUBLIC_KEY'),\n",
    "    secret_key=os.getenv('LANGFUSE_SECRET_KEY'),\n",
    "    host=os.getenv('LANGFUSE_HOST')\n",
    ")\n",
    "\n",
    "def view_recent_traces(limit: int = 5):\n",
    "    \"\"\"Display information about recent traces.\"\"\"\n",
    "    print(f\"\\nüìä Recent Traces (last {limit}):\\n\")\n",
    "    print(\"View detailed traces at: https://cloud.langfuse.com\")\n",
    "    print(\"\\nTraces include:\")\n",
    "    print(\"  - Intent classification step\")\n",
    "    print(\"  - Agent selection logic\")\n",
    "    print(\"  - Vector store retrieval\")\n",
    "    print(\"  - LLM response generation\")\n",
    "    print(\"  - Full execution timeline\")\n",
    "    print(\"  - Token usage and costs\")\n",
    "\n",
    "view_recent_traces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. Evaluator Agent (BONUS)\n",
    "\n",
    "Automated evaluation scores each response on:\n",
    "- **Relevance**: Does it answer the question?\n",
    "- **Completeness**: Is all necessary information included?\n",
    "- **Accuracy**: Is the information correct based on sources?\n",
    "- **Clarity**: Is it well-structured and understandable?\n",
    "\n",
    "Scores are sent to Langfuse for continuous quality monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Evaluator functions defined\n"
     ]
    }
   ],
   "source": [
    "EVALUATOR_PROMPT = \"\"\"You are an AI response quality evaluator for TechCorp's knowledge base system.\n",
    "\n",
    "Evaluate the following response on a scale of 1-5 for each dimension:\n",
    "\n",
    "**Question:** {question}\n",
    "\n",
    "**Answer:** {answer}\n",
    "\n",
    "**Source Documents:** {num_sources} documents retrieved\n",
    "\n",
    "Evaluate on these dimensions:\n",
    "\n",
    "1. **RELEVANCE** (1-5): Does the answer directly address the question?\n",
    "   - 5: Perfectly addresses the question\n",
    "   - 3: Partially relevant\n",
    "   - 1: Completely irrelevant\n",
    "\n",
    "2. **COMPLETENESS** (1-5): Does it include all necessary information?\n",
    "   - 5: Comprehensive, nothing missing\n",
    "   - 3: Covers basics but missing some details\n",
    "   - 1: Incomplete or superficial\n",
    "\n",
    "3. **ACCURACY** (1-5): Is the information factually correct?\n",
    "   - 5: Fully accurate based on context\n",
    "   - 3: Mostly accurate with minor issues\n",
    "   - 1: Contains significant errors\n",
    "\n",
    "4. **CLARITY** (1-5): Is it well-structured and easy to understand?\n",
    "   - 5: Clear, well-organized, professional\n",
    "   - 3: Understandable but could be clearer\n",
    "   - 1: Confusing or poorly structured\n",
    "\n",
    "Respond in this exact format:\n",
    "RELEVANCE: <score>\n",
    "COMPLETENESS: <score>\n",
    "ACCURACY: <score>\n",
    "CLARITY: <score>\n",
    "OVERALL: <average score>\n",
    "REASONING: <brief explanation>\n",
    "\"\"\"\n",
    "\n",
    "def evaluate_response(response: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate a response using LLM-based scoring.\n",
    "    Returns scores for relevance, completeness, accuracy, and clarity.\n",
    "    \"\"\"\n",
    "    evaluation_prompt = EVALUATOR_PROMPT.format(\n",
    "        question=response['question'],\n",
    "        answer=response['answer'],\n",
    "        num_sources=response['num_sources']\n",
    "    )\n",
    "    \n",
    "    eval_response = llm.invoke(\n",
    "        evaluation_prompt,\n",
    "        config={\"callbacks\": [langfuse_handler]}\n",
    "    )\n",
    "    \n",
    "    # Parse evaluation scores\n",
    "    eval_text = eval_response.content\n",
    "    scores = {}\n",
    "    \n",
    "    for line in eval_text.split('\\n'):\n",
    "        if ':' in line:\n",
    "            key, value = line.split(':', 1)\n",
    "            key = key.strip().lower()\n",
    "            if key in ['relevance', 'completeness', 'accuracy', 'clarity', 'overall']:\n",
    "                try:\n",
    "                    scores[key] = float(value.strip().split()[0])\n",
    "                except:\n",
    "                    scores[key] = 0.0\n",
    "            elif key == 'reasoning':\n",
    "                scores[key] = value.strip()\n",
    "    \n",
    "    # Send scores to Langfuse\n",
    "    try:\n",
    "        langfuse.score(\n",
    "            name=\"response_quality\",\n",
    "            value=scores.get('overall', 0),\n",
    "            comment=scores.get('reasoning', ''),\n",
    "            metadata={\n",
    "                'relevance': scores.get('relevance', 0),\n",
    "                'completeness': scores.get('completeness', 0),\n",
    "                'accuracy': scores.get('accuracy', 0),\n",
    "                'clarity': scores.get('clarity', 0),\n",
    "                'category': response['category'],\n",
    "                'agent': response['agent_used']\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Could not send scores to Langfuse: {e}\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def display_evaluation(scores: Dict[str, Any]):\n",
    "    \"\"\"Display evaluation scores in a formatted way.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"QUALITY EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nüìä Relevance:    {scores.get('relevance', 0):.1f}/5\")\n",
    "    print(f\"üìä Completeness: {scores.get('completeness', 0):.1f}/5\")\n",
    "    print(f\"üìä Accuracy:     {scores.get('accuracy', 0):.1f}/5\")\n",
    "    print(f\"üìä Clarity:      {scores.get('clarity', 0):.1f}/5\")\n",
    "    print(f\"\\n‚≠ê Overall Score: {scores.get('overall', 0):.1f}/5\")\n",
    "    \n",
    "    if 'reasoning' in scores:\n",
    "        print(f\"\\nüí≠ Reasoning: {scores['reasoning']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"‚úì Evaluator functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "# EVALUATOR DEMO\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "Query: What is the parental leave policy for non-birth parents?\n",
      "============================================================\n",
      "\n",
      "üìã Classification: HR\n",
      "üéØ Routing to HR Agent...\n",
      "\n",
      "\n",
      "============================================================\n",
      "RESPONSE\n",
      "============================================================\n",
      "\n",
      "The parental leave policy for non-birth parents at TechCorp includes the following provisions:\n",
      "\n",
      "- **Duration of Leave:** Non-birth parents are entitled to 8 weeks (320 hours) of paid leave.\n",
      "- **Flexibility in Leave Period:** The leave can be taken within 12 months of the birth of the child. Additionally, it may be split into two separate 4-week periods to provide flexibility.\n",
      "- **Inclusivity:** The policy includes same-sex partners, applying equally to fathers and adoptive parents.\n",
      "- **Benefits:** Non-birth parents receive the same benefits during their leave as other types of parental leave, ensuring job protection and continuation of benefits.\n",
      "- **Parental Leave Process:**\n",
      "  1. Non-birth parents should notify HR and their manager as soon as possible about their intention to take parental leave.\n",
      "  2. They must submit a leave request at least 30 days before the intended start date of their leave.\n",
      "  3. A parental leave application needs to be completed.\n",
      "  4. Coordination with HR on the leave schedule is required to ensure all paperwork and requirements are met.\n",
      "  5. Arrangements for coverage during the leave period should be made with the manager to ensure smooth operations in the non-birth parent's absence.\n",
      "\n",
      "This policy is designed to support non-birth parents in balancing their work responsibilities with the needs of their growing families, recognizing the importance of bonding time with a new child.\n",
      "\n",
      "\n",
      "üìö Sources: 5 documents retrieved\n",
      "\n",
      "Top source: data/hr_docs/leave_policies.md\n",
      "\n",
      "============================================================\n",
      "\n",
      "üîç Running automated evaluation...\n",
      "  ‚ö†Ô∏è  Could not send scores to Langfuse: 'Langfuse' object has no attribute 'score'\n",
      "\n",
      "============================================================\n",
      "QUALITY EVALUATION\n",
      "============================================================\n",
      "\n",
      "üìä Relevance:    5.0/5\n",
      "üìä Completeness: 5.0/5\n",
      "üìä Accuracy:     5.0/5\n",
      "üìä Clarity:      5.0/5\n",
      "\n",
      "‚≠ê Overall Score: 5.0/5\n",
      "\n",
      "üí≠ Reasoning: The response directly addresses the question about the parental leave policy for non-birth parents at TechCorp, providing detailed information on the duration, flexibility, inclusivity, benefits, and the process for taking leave. It includes all necessary information that a non-birth parent would need to know about the policy, ensuring completeness. The information presented is assumed to be accurate based on the context provided, with no apparent errors or inaccuracies. The answer is well-structured and easy to understand, with clear headings and a logical flow that guides the reader through the policy details. This makes the response clear and professional. Overall, the response effectively meets the criteria for a high-quality answer in all dimensions evaluated.\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test evaluation on a sample query\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# EVALUATOR DEMO\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "test_question = \"What is the parental leave policy for non-birth parents?\"\n",
    "response = route_query(test_question)\n",
    "display_response(response)\n",
    "\n",
    "print(\"\\nüîç Running automated evaluation...\")\n",
    "scores = evaluate_response(response)\n",
    "display_evaluation(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. Batch Testing\n",
    "\n",
    "Run multiple test queries and evaluate all responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Batch testing function defined\n"
     ]
    }
   ],
   "source": [
    "def run_batch_tests(questions: List[str], evaluate: bool = True):\n",
    "    \"\"\"\n",
    "    Run a batch of test questions through the system.\n",
    "    Optionally evaluate each response.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(\"\\n\" + \"#\"*60)\n",
    "    print(f\"# BATCH TEST: {len(questions)} queries\")\n",
    "    print(\"#\"*60)\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"\\n\\n[{i}/{len(questions)}] Testing: {question[:60]}...\")\n",
    "        \n",
    "        # Get response\n",
    "        response = route_query(question)\n",
    "        \n",
    "        # Evaluate if requested\n",
    "        if evaluate:\n",
    "            print(\"  Evaluating...\")\n",
    "            scores = evaluate_response(response)\n",
    "            response['evaluation'] = scores\n",
    "            print(f\"  ‚≠ê Score: {scores.get('overall', 0):.1f}/5\")\n",
    "        \n",
    "        results.append(response)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\\n\" + \"=\"*60)\n",
    "    print(\"BATCH TEST SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    categories = {}\n",
    "    for result in results:\n",
    "        cat = result['category']\n",
    "        categories[cat] = categories.get(cat, 0) + 1\n",
    "    \n",
    "    print(\"\\nüìä Routing Distribution:\")\n",
    "    for cat, count in categories.items():\n",
    "        print(f\"  - {cat}: {count} queries ({count/len(questions)*100:.1f}%)\")\n",
    "    \n",
    "    if evaluate:\n",
    "        avg_score = sum(r.get('evaluation', {}).get('overall', 0) for r in results) / len(results)\n",
    "        print(f\"\\n‚≠ê Average Quality Score: {avg_score:.2f}/5\")\n",
    "        \n",
    "        low_scores = [r for r in results if r.get('evaluation', {}).get('overall', 0) < 3]\n",
    "        if low_scores:\n",
    "            print(f\"\\n‚ö†Ô∏è  {len(low_scores)} response(s) scored below 3.0 - review recommended\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úì Batch testing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "## What We Built\n",
    "\n",
    "1. **Multi-Agent RAG System** with three specialized agents (HR, Tech, Finance)\n",
    "2. **Intelligent Orchestrator** that classifies and routes queries\n",
    "3. **Complete Langfuse Integration** for tracing and debugging\n",
    "4. **Automated Evaluator** for response quality scoring\n",
    "5. **Production-Ready Components** using LangChain\n",
    "\n",
    "## Technical Decisions\n",
    "\n",
    "### Why LangChain?\n",
    "- **Production-grade components**: RetrievalQA, vector stores, chains\n",
    "- **Maintainability**: Standard abstractions, well-documented\n",
    "- **Extensibility**: Easy to add new agents or modify retrieval\n",
    "- **Community support**: Active development and plugins\n",
    "\n",
    "### Why Separate Vector Stores?\n",
    "- **Domain isolation**: Each agent has specialized knowledge\n",
    "- **Better retrieval**: More focused results per domain\n",
    "- **Scalability**: Can update one domain without affecting others\n",
    "- **Performance**: Smaller vector spaces = faster search\n",
    "\n",
    "### Why Orchestrator-Based Routing?\n",
    "- **Flexibility**: Can handle complex, multi-domain queries\n",
    "- **Accuracy**: LLM classification more robust than keyword matching\n",
    "- **Debuggability**: Clear decision trail in Langfuse\n",
    "- **Extensibility**: Easy to add new categories\n",
    "\n",
    "### Why Langfuse for Tracing?\n",
    "- **Full visibility**: Every step of execution logged\n",
    "- **Production monitoring**: Track quality over time\n",
    "- **Debugging**: Identify misrouting and bad retrievals\n",
    "- **Analytics**: Understand usage patterns and performance\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To use this system:\n",
    "1. Set up `.env` file with your API keys\n",
    "2. Run cells in order to create vector stores\n",
    "3. Test with your own queries\n",
    "4. View traces in Langfuse dashboard\n",
    "5. Monitor quality scores over time\n",
    "\n",
    "## Access Your Traces\n",
    "\n",
    "View detailed execution traces at: **https://cloud.langfuse.com**\n",
    "\n",
    "You'll see:\n",
    "- Complete query execution paths\n",
    "- Token usage and costs\n",
    "- Retrieval relevance\n",
    "- Response quality scores\n",
    "- Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "limos_multi_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
